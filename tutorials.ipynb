{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blog Agent Tutorial\n",
    "Hereâ€™s how to build a Blog Agent that collects content from a website, generates images, and writes a blog post.\n",
    "\n",
    "**Step 1: Set API Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wyge.models.openai import ChatOpenAI\n",
    "from wyge.tools.prebuilt_tools import extract_relevant_sections_from_website, generate_images_and_add_to_blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Initialize Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_tool = extract_relevant_sections_from_website()  # Tool to scrape a website\n",
    "blog_tool = generate_images_and_add_to_blog()  # Tool to generate image and add to blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Initialize LLM with Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(tools=[blog_tool, web_tool], return_tool_output=True, memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Gather Context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"How to tackle AI\"\n",
    "url = \"https://www.digiotai.com\"\n",
    "\n",
    "# Collect content from website\n",
    "prompt1 = (\n",
    "    f\"Gather relevant information about the topic from the website.\\n\"\n",
    "    f\"Topic: {topic}\\n\"\n",
    "    f\"Website: {url}\"\n",
    ")\n",
    "context = llm.run(prompt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Generate Blog Post**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = (\n",
    "    \"Write a comprehensive blog post with images for a company based on the following details:\\n\\n\"\n",
    "    f\"Topic: {topic}\\n\"\n",
    "    f\"Summarized content from company's website: {context}\\n\\n\"\n",
    "    \"The blog should include an engaging introduction to the topic, followed by detailed sections about how the company addresses the topic, \"\n",
    "    \"and a conclusion summarizing the key points. Generate '<image> image prompt here </image>' where necessary.\"\n",
    ")\n",
    "blog_content = llm.run(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkedIn Agent Tutorial\n",
    "Create a LinkedIn agent that extracts key takeaways from a YouTube video and posts them on LinkedIn.\n",
    "\n",
    "**Step 1: Set API Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vyzeai.models.openai import ChatOpenAI\n",
    "from vyzeai.tools.prebuilt_tools import youtube_transcript_loader, post_on_linkedin, generate_image_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Initialize Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_tool = youtube_transcript_loader()  # Extract YouTube transcript\n",
    "img_tool = generate_image_openai()  # Generate image\n",
    "linkedin_tool = post_on_linkedin()  # Post on LinkedIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Initialize LLM with Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(tools=[yt_tool, img_tool, linkedin_tool], memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Extract Transcript and Create Post**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=e_uOigt1w1o\"\n",
    "\n",
    "prompt1 = (\n",
    "    \"You are an AI agent specialized in creating LinkedIn posts from YouTube videos. \"\n",
    "    \"Your task is to extract the key takeaways and insights from the following video and create a professional, \"\n",
    "    \"engaging LinkedIn post that summarizes the content.\"\n",
    "    f\"\\nYouTube video URL: {video_url}\"\n",
    ")\n",
    "linkedin_post = llm.run(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Generator\n",
    "\n",
    "In this tutorial, you will learn how to generate synthetic data using VyzeAI's OpenAI integration. We will take a dataset from an Excel file, generate additional synthetic rows that follow the same structure, and append them to the original data.\n",
    "\n",
    "#### Step 1: Setup Dependencies\n",
    "\n",
    "Make sure you have the following dependencies installed:\n",
    "\n",
    "```bash\n",
    "pip install pandas openai vyzeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Load the Data and Initialize the Model\n",
    "First, load the Excel data and initialize the ChatOpenAI model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vyzeai.models.openai import ChatOpenAI\n",
    "\n",
    "# File path to the Excel file\n",
    "file_path = \"sample_data.xlsx\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Take a sample of the last 50 rows\n",
    "sample_data = data.tail(50)\n",
    "\n",
    "# Convert the sample data into a CSV-like string format\n",
    "sample_str = sample_data.to_csv(index=False, header=False)\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = ChatOpenAI(memory=True, api_key=\"your-api-key-here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Generate Synthetic Data\n",
    "Now, we will generate synthetic data by prompting the model to create rows based on the structure of the existing dataset. The code generates data in chunks to ensure the model can process the request efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows to generate in each chunk\n",
    "chunk_size = 50\n",
    "\n",
    "# Total number of rows to generate\n",
    "num_rows = 50\n",
    "\n",
    "# System message to instruct the model to behave as a synthetic data generator\n",
    "system_message = \"You are a synthetic data generator. Provide output in the specified format without extra text.\"\n",
    "\n",
    "# Store the generated data\n",
    "generated_rows = []\n",
    "rows_generated = 0\n",
    "\n",
    "# Main loop to generate synthetic data until the desired number of rows is reached\n",
    "while rows_generated < num_rows:\n",
    "    # Use previously generated rows or the original sample for generation\n",
    "    current_sample_str = \"\\n\".join([\",\".join(row) for row in generated_rows[-50:]]) if generated_rows else sample_str\n",
    "    \n",
    "    # Calculate how many rows to generate in this batch\n",
    "    rows_to_generate = min(chunk_size, num_rows - rows_generated)\n",
    "    \n",
    "    # Construct the prompt for the model\n",
    "    prompt = (f\"Generate {rows_to_generate} rows of synthetic data based on this sample:\\n\\n{current_sample_str}\\n\"\n",
    "              \"Output as pipe-separated values ('|') without column headers.\")\n",
    "\n",
    "    # Get the generated data from the model\n",
    "    generated_data = llm.run(prompt, system_message=system_message, return_tool_output=True)\n",
    "    \n",
    "    # Parse the generated data into rows\n",
    "    rows = [row.split(\"|\") for row in generated_data.strip().split(\"\\n\") if row]\n",
    "    \n",
    "    # Append the new rows to the generated rows\n",
    "    generated_rows.extend(rows)\n",
    "    rows_generated += len(rows)\n",
    "\n",
    "# Create a DataFrame from the generated rows\n",
    "generated_df = pd.DataFrame(generated_rows, columns=data.columns)\n",
    "\n",
    "# Combine the original and synthetic data\n",
    "combined_df = pd.concat([data, generated_df], ignore_index=True)\n",
    "\n",
    "print(generated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
